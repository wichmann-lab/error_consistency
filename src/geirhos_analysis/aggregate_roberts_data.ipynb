{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Robert's data\n",
    "\n",
    "The point of this notebook is to aggregate Robert's data into one joined df for easy access, which we save to parquet.\n",
    "\n",
    "Next, the `bootstrap.py` script should be run to bootstrap confidence intervals.\n",
    "\n",
    "Then, `plot_roberts_data.ipynb` should be run to recreate the plots.\n",
    "\n",
    "Robert has two sets of human data:\n",
    "- for the 2018 NeurIPS paper, they didn't yet plan to calculate EC, so the humans didn't see the same images.\n",
    "- for the closing-the-gap-paper, they re-ran the experiment, this time showing the same images to all humans.\n",
    "\n",
    "So we can't use the 2018 data at all, and the model data for the closing-the-gap paper is not in the public repo.\n",
    "\n",
    "Robert gave us this data, and this notebook assumes that it is located in a folder called `modelvshuman-raw-data`, which should exist at the same top-level location as our repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils import filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eidolon_condition(eid_condition: str) -> str:\n",
    "    \"\"\"Get the condition of the eidolon experiment from the condition string.\"\"\"\n",
    "    parts = eid_condition.split(\"-\")\n",
    "    return str(int(np.log2(int(parts[0]))))\n",
    "\n",
    "\n",
    "def fix_conditions(row):\n",
    "    exp = row[\"experiment\"]\n",
    "    condition = row[\"condition\"]\n",
    "\n",
    "    # first, fix eidolons from strings to 1 - 7\n",
    "    if \"eidolon\" in exp:\n",
    "        condition = get_eidolon_condition(condition)\n",
    "\n",
    "    # second, remove nans\n",
    "    if condition == np.nan or condition == \"nan\" or pd.isna(condition):\n",
    "        condition = 0\n",
    "\n",
    "    return condition\n",
    "\n",
    "\n",
    "def get_img_identifier(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Create a unique image identifier from the image name.\n",
    "\n",
    "    :param row: one row of the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    img_name = row[\"imagename\"]\n",
    "    experiment = row[\"experiment\"]\n",
    "    condition = row[\"condition\"]\n",
    "\n",
    "    if experiment in [\"cue-conflict\", \"edge\", \"silhouette\", \"sketch\", \"stylized\"]:\n",
    "        img_id = img_name.split(\"_\")[-1].split(\".png\")[0]\n",
    "    else:\n",
    "        # standard experiments\n",
    "        assert len(img_name.split(\"_\")) == 8, \"img_name should have 8 parts\"\n",
    "        _idx, _exp, _subj, _cond, category, number, cls_id, img_id = img_name.split(\"_\")\n",
    "        img_id = f\"{cls_id}-{img_id.split('.png')[0]}\"\n",
    "\n",
    "    return f\"{experiment}_{condition}_{img_id}\"\n",
    "\n",
    "\n",
    "def aggregate_data(root: str) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    _, dirs, files = next(os.walk(root))\n",
    "    for dir in dirs:\n",
    "        if dir in [\n",
    "            \"colour\",\n",
    "            \"contrast\",\n",
    "            \"eidolonI\",\n",
    "            \"eidolonII\",\n",
    "            \"eidolonIII\",\n",
    "            \"false-colour\",\n",
    "            \"high-pass\",\n",
    "            \"low-pass\",\n",
    "            \"power-equalisation\",\n",
    "            \"rotation\",\n",
    "            \"phase-scrambling\",\n",
    "            \"uniform-noise\",\n",
    "            \"cue-conflict\",\n",
    "            \"edge\",\n",
    "            \"silhouette\",\n",
    "            \"sketch\",\n",
    "            \"stylized\",\n",
    "        ]:\n",
    "            _, _, files = next(os.walk(pjoin(root, dir)))\n",
    "            for f in files:\n",
    "                if f.endswith(\".csv\"):\n",
    "                    sub_df = pd.read_csv(pjoin(root, dir, f))\n",
    "                    sub_df[\"experiment\"] = dir\n",
    "                    sub_df[\"correct\"] = sub_df[\"object_response\"] == sub_df[\"category\"]\n",
    "                    dfs.append(sub_df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    df[\"condition\"] = df.apply(\n",
    "        fix_conditions,\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"img_identifier\"] = df.apply(get_img_identifier, axis=1)\n",
    "    df[\"subject_type\"] = df[\"subj\"].apply(\n",
    "        lambda x: \"human\" if \"subject\" in x else \"machine\"\n",
    "    )\n",
    "    df.drop(columns=[\"Session\", \"session\", \"trial\", \"rt\", \"imagename\"], inplace=True)\n",
    "\n",
    "    # On silhouette data and potentially elsewhere, more models were evaluated.\n",
    "    # Here, I make sure that we have exactly the same set of models in all experiments\n",
    "    color_models = df[df[\"experiment\"] == \"colour\"][\"subj\"].unique()\n",
    "    df = df[(df[\"subj\"].isin(color_models)) | (df[\"subj\"].str.contains(\"subject-\"))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aggregate_data(\"../../../modelvshuman-raw-data/\")\n",
    "\n",
    "# properly setting the column types because otherwise pd defaults to using slow comparisons\n",
    "df[\"subj\"] = df[\"subj\"].astype(\"category\")\n",
    "df[\"object_response\"] = df[\"object_response\"].astype(\"category\")\n",
    "df[\"category\"] = df[\"category\"].astype(\"category\")\n",
    "df[\"condition\"] = df[\"condition\"].astype(str).astype(\"category\")\n",
    "df[\"experiment\"] = df[\"experiment\"].astype(\"category\")\n",
    "df[\"img_identifier\"] = df[\"img_identifier\"].astype(\"string\")\n",
    "df[\"subject_type\"] = df[\"subject_type\"].astype(\"category\")\n",
    "\n",
    "print(\"Created df with\", len(df), \"lines!\")\n",
    "print(df.info())\n",
    "\n",
    "# using parquet files to store this, because it respects data types\n",
    "df.to_parquet(\"data/roberts_raw_data.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy per experiment, condition and model for adding them to the countour-plot\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"data/roberts_raw_data.parquet\")\n",
    "df = filter_df(df)\n",
    "df[\"correct\"] = df[\"correct\"].astype(float)\n",
    "accuracies = (\n",
    "    df.groupby([\"experiment\", \"condition\", \"subj\"], observed=True)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "accuracies.to_csv(\"data/accuracies.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
